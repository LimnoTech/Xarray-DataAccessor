{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "from read_into_xarray import DataAccessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using shapefile to select AOI\n",
      "ERA5DataAccessor object successfully initialized! Use ERA5DataAccessor.inputs_dict to verify your inputs.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "era5_datasets_info.py was found but not era5_data_accessor.py! Did you move or delete files?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\xrnogueira\\Documents\\ERA5-to-Xarray\\read_into_xarray\\data_accessor.py:207\u001b[0m, in \u001b[0;36mDataAccessor._get_era5_accessor\u001b[1;34m()\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mread_into_xarray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mera5_data_accessor\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mera5_data_accessor\u001b[39;00m\n\u001b[0;32m    208\u001b[0m     \u001b[39mreturn\u001b[39;00m era5_data_accessor\u001b[39m.\u001b[39mERA5DataAccessor\n",
      "File \u001b[1;32mc:\\Users\\xrnogueira\\Documents\\ERA5-to-Xarray\\read_into_xarray\\era5_data_accessor.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxarray\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxr\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcdsapi\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgeopandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cdsapi'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m\n\u001b[0;32m      6\u001b[0m VARIABLES \u001b[39m=\u001b[39m [\n\u001b[0;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m2m_temperature\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m2m_dewpoint_temperature\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m10m_v_component_of_wind\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m ]\n\u001b[0;32m     15\u001b[0m data_accessor \u001b[39m=\u001b[39m DataAccessor(\n\u001b[0;32m     16\u001b[0m     dataset_name\u001b[39m=\u001b[39mDATASET_NAME,\n\u001b[0;32m     17\u001b[0m     variables\u001b[39m=\u001b[39mVARIABLES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     multithread\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m ds \u001b[39m=\u001b[39m data_accessor\u001b[39m.\u001b[39;49mget_data()\n",
      "File \u001b[1;32mc:\\Users\\xrnogueira\\Documents\\ERA5-to-Xarray\\read_into_xarray\\data_accessor.py:369\u001b[0m, in \u001b[0;36mDataAccessor.get_data\u001b[1;34m(self, overwrite, dask_client_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    363\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mA xarray Dataset is already saved to this object. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    364\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mTo overwrite set .pull_data param:overwrite=True\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    365\u001b[0m         )\n\u001b[0;32m    367\u001b[0m \u001b[39m# get accessor and pull data\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[39m# TODO: debug wierd dask behavior\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m data_accessor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupported_accessors[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_key](\n\u001b[0;32m    370\u001b[0m     dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name,\n\u001b[0;32m    371\u001b[0m     multithread\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultithread,\n\u001b[0;32m    372\u001b[0m     \u001b[39m# use_dask=DASK_DISTRIBUTE,\u001b[39;00m\n\u001b[0;32m    373\u001b[0m     dask_client_kwargs\u001b[39m=\u001b[39mdask_client_kwargs,\n\u001b[0;32m    374\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m    375\u001b[0m )\n\u001b[0;32m    377\u001b[0m dataset \u001b[39m=\u001b[39m data_accessor\u001b[39m.\u001b[39mget_data(\n\u001b[0;32m    378\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables,\n\u001b[0;32m    379\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_dt,\n\u001b[0;32m    380\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend_dt,\n\u001b[0;32m    381\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbbox,\n\u001b[0;32m    382\u001b[0m )\n\u001b[0;32m    383\u001b[0m \u001b[39m# set object attribute to point to the dataset\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xrnogueira\\Documents\\ERA5-to-Xarray\\read_into_xarray\\data_accessor.py:231\u001b[0m, in \u001b[0;36mDataAccessor.supported_accessors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_supported_accessors \u001b[39m=\u001b[39m {}\n\u001b[0;32m    230\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupported_datasets_info\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m--> 231\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_supported_accessors[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessors[key]()\n\u001b[0;32m    233\u001b[0m \u001b[39m# check if things look correct\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_supported_accessors) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupported_datasets_info):\n",
      "File \u001b[1;32mc:\\Users\\xrnogueira\\Documents\\ERA5-to-Xarray\\read_into_xarray\\data_accessor.py:210\u001b[0m, in \u001b[0;36mDataAccessor._get_era5_accessor\u001b[1;34m()\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[39mreturn\u001b[39;00m era5_data_accessor\u001b[39m.\u001b[39mERA5DataAccessor\n\u001b[0;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    211\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mera5_datasets_info.py was found but not era5_data_accessor.py! \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    212\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mDid you move or delete files?\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    213\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: era5_datasets_info.py was found but not era5_data_accessor.py! Did you move or delete files?"
     ]
    }
   ],
   "source": [
    "START_TIME = '9/1/2015'\n",
    "END_TIME = '9/30/2016'\n",
    "AOI_SHP = Path(Path.cwd() / 'lake_erie_data/LEEM_boundary.shp')\n",
    "RESOLUTION = 100 # meters\n",
    "DATASET_NAME = 'reanalysis-era5-single-levels'\n",
    "VARIABLES = [\n",
    "    '2m_temperature',\n",
    "    '2m_dewpoint_temperature',\n",
    "    'total_cloud_cover',\n",
    "    'mean_surface_downward_short_wave_radiation_flux',\n",
    "    '10m_u_component_of_wind',\n",
    "    '10m_v_component_of_wind',\n",
    "]\n",
    "\n",
    "data_accessor = DataAccessor(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    variables=VARIABLES,\n",
    "    start_time=START_TIME,\n",
    "    end_time=END_TIME,\n",
    "    coordinates=None,\n",
    "    csv_of_coords=None,\n",
    "    shapefile=AOI_SHP,\n",
    "    raster=None,\n",
    "    multithread=True,\n",
    ")\n",
    "\n",
    "ds = data_accessor.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dict = {'index': 1, 'wa': [200, 300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = t_dict.pop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wa': [200, 300]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = pd.to_datetime('9/1/2016')\n",
    "end_dt = pd.to_datetime('2/1/2018') - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "5\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "keys = list([2, 5, 23,1, 0])\n",
    "keys.sort()\n",
    "for i in keys:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-01-31 00:00:00')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [\n",
    "            executor.submit(retrieve, client, request.copy(), date) for date in DATES\n",
    "        ]\n",
    "        for f in as_completed(futures):\n",
    "            try:\n",
    "                print(f.result())\n",
    "            except:\n",
    "                print(\"could not retrieve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2001-01-01 00:00:00')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('2001-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "executer = ThreadPoolExecutor(max_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5000468619034717 -- 2023-02-06 23:01:26.557012\n",
      "0.4999993910621658 -- 2023-02-06 23:01:26.558012\n",
      "0.4999791634091358 -- 2023-02-06 23:01:26.558012\n",
      "0.5000709779321063 -- 2023-02-06 23:01:26.558012\n",
      "0.5000177987353763 -- 2023-02-06 23:01:26.558012\n",
      "0.49997436850748916 -- 2023-02-06 23:01:26.558012\n",
      "0.49997228635844154 -- 2023-02-06 23:01:26.558012\n",
      "0.5000079418225598 -- 2023-02-06 23:01:26.558012\n",
      "0.5000004192951776 -- 2023-02-06 23:01:26.558012\n",
      "0.5000037636331556 -- 2023-02-06 23:01:26.558012\n"
     ]
    }
   ],
   "source": [
    "# as_completed is an iterator\n",
    "for f in as_completed(futures):\n",
    "    print(f'{f.result()} -- {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000037636331556"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0d80410862304beb58e47d8f6de129deb046d897f43b6667c8c72010b2a4021"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
