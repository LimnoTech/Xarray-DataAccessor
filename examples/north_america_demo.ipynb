{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Xarray-DataAccessor` + `ModelMyWatershed API` + `FCPGtools` Demo Notebook\n",
    "==========================================================================\n",
    "\n",
    "**Author:** [Xavier R Nogueira](https://github.com/xaviernogueira)\n",
    "\n",
    "**Notebook Steps:**\n",
    "1. Using the `xarray_data_accessor.DataAccessorFactory` library to search available datasets/variables.\n",
    "2. Use the Model My Watershed API to delineate a the watershed boundary for our lat/lon (CONUS only).\n",
    "3. Read-in hourly ERA5 precipitation data from [Planet OS's AWS S3 bucket](https://github.com/planet-os/notebooks/blob/master/aws/era5-pds.md) for our South American basin of choice using `xarray_data_accessor`.\n",
    "4. Read in [NASA Digital Elevation Model (DEM) data](https://lpdaac.usgs.gov/products/nasadem_hgtv001/) for out watershed using `xarray_data_accessor`.\n",
    "5. Convert our DEM to a D8 Flow Direction Raster using `pysheds`.\n",
    "6. Use `fcpgtools` to resample our precipitation data to match the resolution of the FDR.\n",
    "7. Use `fcpgtools` to calculate precipitation accumulation for all hourly time steps.\n",
    "\n",
    "All the while we will be creating interactive plots/maps using [`hvplot`](https://hvplot.holoviz.org/) and [`geoviews`](https://geoviews.org/).\n",
    "\n",
    "**OR just get the aspect directly** https://lpdaac.usgs.gov/products/nasadem_scv001/\n",
    "\n",
    "Investigate reading with fsspec? https://github.com/microsoft/AIforEarthDataSets/blob/main/data/nasadem-nc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import requests\n",
    "import geopandas\n",
    "import shapely\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "import cartopy.crs as ccrs\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import pysheds\n",
    "from typing import (\n",
    "    List,\n",
    "    Optional,\n",
    "    TypedDict,\n",
    ")\n",
    "\n",
    "# import our library\n",
    "import xarray_data_accessor\n",
    "\n",
    "# import our username/password\n",
    "import auth_config\n",
    "from auth_config import (\n",
    "    MMW_AUTH_DICT,\n",
    "    EARTH_DATA_AUTH_DICT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# env not liking fcpgtools - I cloned the repo and added it to my environment (also pip installed pysheds)\n",
    "import fcpgtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ—ƒï¸ Explore data availability ðŸ—ƒï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we see what datasets can be accessed by different 'data accessors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets start by seeing which DataAccessor objects are currently available\n",
    "xarray_data_accessor.DataAccessorFactory.data_accessor_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next lets see what datasets each can access\n",
    "xarray_data_accessor.DataAccessorFactory.supported_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next we see which ERA5 hourly variables can be fetched with the `AWSDataAccessor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xarray_data_accessor.DataAccessorFactory.supported_variables(\n",
    "    data_accessor_name='AWSDataAccessor',\n",
    "    dataset_name='reanalysis-era5-single-levels',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We also explore NASA elevation products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xarray_data_accessor.DataAccessorFactory.supported_variables(\n",
    "    data_accessor_name='NASA_LPDAAC_Accessor',\n",
    "    dataset_name='NASADEM_NC',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒ„ Define a watershed AOI using Model My Watershed API ðŸŒ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import (\n",
    "    Polygon,\n",
    "    Point,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select a lat/long in CONUS\n",
    "lat = 38.971125\n",
    "lon = -77.042225\n",
    "\n",
    "# get point as a GeoDataFrame\n",
    "point_gdf = geopandas.GeoDataFrame({'geometry': [Point((lon, lat))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mmw_base_url = r'https://modelmywatershed.org/api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# get a token code\n",
    "token_response = requests.post(\n",
    "    mmw_base_url + '/token/',\n",
    "    data=auth_config.MMW_AUTH_DICT,\n",
    ")\n",
    "token = dict(token_response.json())['token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define function to handle API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LocationDict(TypedDict):\n",
    "    location: List[float]\n",
    "    snappingOn: Optional[str]\n",
    "    simplify: Optional[int]\n",
    "    datasource: Optional[str]\n",
    "\n",
    "\n",
    "def get_watershed(\n",
    "    session: requests.Session,\n",
    "    location_dict: LocationDict,\n",
    "    mmw_base_url: str,\n",
    ") -> geopandas.GeoDataFrame:\n",
    "    \"\"\"Uses the Model My Watershed API to get a boundary\"\"\"\n",
    "    # init the job\n",
    "    job_dict = mmw_session.post(\n",
    "        mmw_base_url + '/watershed/',\n",
    "        data=json.dumps(location_dict),\n",
    "    )\n",
    "\n",
    "    # use the job ID to check up on it\n",
    "    done = False\n",
    "    while not done:\n",
    "        status_dict = dict(session.get(mmw_base_url + f'/jobs/{dict(job_dict.json())[\"job\"]}').json())\n",
    "        if status_dict['status'] == 'complete':\n",
    "            done = True\n",
    "            print('Delineation worked! Returning results...')\n",
    "        elif status_dict['status'] == 'failed':\n",
    "            raise ValueError(f'API request failed! See response: {status_dict}')\n",
    "\n",
    "    watershed_dict = status_dict['result']['watershed']\n",
    "    watershed_poly = Polygon(watershed_dict['geometry']['coordinates'][0])\n",
    "    return geopandas.GeoDataFrame({'geometry': [watershed_poly]}, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start a requests session\n",
    "mmw_session = requests.Session()\n",
    "mmw_session.headers.update({\n",
    "    'Authorization': 'Token ' + token,\n",
    "    'Content-Type': 'application/json'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "location_dict = {\n",
    "    'location': [lat, lon],\n",
    "    'snappingOn': True,\n",
    "    'dataSource': 'nhd',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "watershed = get_watershed(\n",
    "    mmw_session,\n",
    "    location_dict,\n",
    "    mmw_base_url,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot our basin(s) and point\n",
    "watershed.hvplot(\n",
    "    crs=watershed.crs.to_wkt(),\n",
    "    tiles='StamenTerrainRetina',\n",
    "    width=500,\n",
    "    height=500,\n",
    "    fill_color=None,\n",
    "    line_width=4,\n",
    "    line_color='blue',\n",
    ") * point_gdf.hvplot(\n",
    "    color='red',\n",
    "    crs=watershed.crs.to_wkt(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ›°ï¸ Read-in ERA5 precipitation data from the Planet OS AWS cloud bucket ðŸ›°ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xarray_data = xarray_data_accessor.get_xarray_dataset(\n",
    "    data_accessor_name='AWSDataAccessor',\n",
    "    dataset_name='reanalysis-era5-single-levels',\n",
    "    variables=[\n",
    "        'precipitation_amount_1hour_Accumulation',\n",
    "    ],\n",
    "    start_time='2021-08-09',\n",
    "    end_time='2021-08-12',\n",
    "    shapefile=watershed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xarray_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xarray_data.precipitation_amount_1hour_Accumulation.hvplot(\n",
    "    x='time',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ›°ï¸ Read-in NASA DEM data from their API ðŸ›°ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# TODO: CHANGE THIS\n",
    "dem_data = xarray_data_accessor.get_xarray_dataset(\n",
    "    data_accessor_name='NASA_LPDAAC_Accessor',\n",
    "    dataset_name='NASADEM_NC',\n",
    "    variables=[\n",
    "        'DEM',\n",
    "    ],\n",
    "    start_time='2021-07-15',\n",
    "    end_time='2021-07-18',\n",
    "    shapefile=watershed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot a central point over time\n",
    "gc.collect()\n",
    "dem_data.NASADEM_HGT.hvplot(\n",
    "    crs=watershed.crs.to_wkt(),\n",
    "    tiles='StamenTerrainRetina',\n",
    "    width=500,\n",
    "    height=500,\n",
    ") * watershed.hvplot(\n",
    "    crs=watershed.crs.to_wkt(),\n",
    "    fill_color=None,\n",
    "    line_width=4,\n",
    "    line_color='green',\n",
    ") * point_gdf.hvplot(\n",
    "    color='red',\n",
    "    crs=watershed.crs.to_wkt(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§° Prep `FCPGtools` Inputs ðŸ§°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert DEM to a D8 Flow Direction Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# convert to slope\n",
    "slope = np.arctan(dem_data.NASADEM_HGT.differentiate('lat') / np.sqrt(dem_data.NASADEM_HGT.differentiate('lon')**2 + dem_data.NASADEM_HGT.differentiate('lat')**2))\n",
    "\n",
    "# fill flats and nodata\n",
    "slope = slope.interpolate_na(dim='lat', method='linear')\n",
    "del dem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert to aspect\n",
    "aspect = np.rad2deg(np.arctan2(slope.differentiate('lon'), slope.differentiate('lat')))\n",
    "del slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aspect_to_d8(aspect_angle: int, d8_format: str = 'esri') -> xr.DataArray:\n",
    "    d8_direction = np.full(aspect_angle.shape, 255)\n",
    "\n",
    "    # get the D8 FDR values from fcpgtools\n",
    "    conv_dict = fcpgtools.custom_types.D8ConversionDicts[d8_format]\n",
    "\n",
    "    d8_direction[(aspect_angle >= 337.5) | (aspect_angle < 22.5)] = conv_dict['north']\n",
    "    d8_direction[(aspect_angle >= 22.5) & (aspect_angle < 67.5)] = conv_dict['northeast']\n",
    "    d8_direction[(aspect_angle >= 67.5) & (aspect_angle < 112.5)] = conv_dict['east']\n",
    "    d8_direction[(aspect_angle >= 112.5) & (aspect_angle < 157.5)] = conv_dict['southeast']\n",
    "    d8_direction[(aspect_angle >= 157.5) & (aspect_angle < 202.5)] = conv_dict['south']\n",
    "    d8_direction[(aspect_angle >= 202.5) & (aspect_angle < 247.5)] = conv_dict['southwest']\n",
    "    d8_direction[(aspect_angle >= 247.5) & (aspect_angle < 292.5)] = conv_dict['west']\n",
    "    d8_direction[(aspect_angle >= 292.5) & (aspect_angle < 337.5)] = conv_dict['northwest']\n",
    "\n",
    "    return d8_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fdr = xr.apply_ufunc(\n",
    "    aspect_to_d8,\n",
    "    aspect.compute(),\n",
    "    output_dtypes=[np.int32],\n",
    ")\n",
    "fdr = fdr.rio.write_crs(4326)\n",
    "del aspect\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip to our FDR to our basin AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clip to the bbox\n",
    "fdr = fcpgtools.clip(\n",
    "    fdr,\n",
    "    match_shapefile=watershed,\n",
    ")\n",
    "# mask to only include values in our shapefile\n",
    "fdr = fcpgtools.spatial_mask(\n",
    "    fdr,\n",
    "    mask_shp=watershed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdr.where(fdr != 255, np.nan).hvplot(\n",
    "    crs=fdr.rio.crs.to_wkt(),\n",
    "    tiles='StamenTerrainRetina',\n",
    "    width=500,\n",
    "    height=500,\n",
    "    clim=(0, 250),\n",
    "    cmap='Category10',\n",
    ") * watershed.hvplot(\n",
    "    crs=watershed.crs.to_wkt(),\n",
    "    fill_color=None,\n",
    "    line_width=4,\n",
    "    line_color='black',\n",
    ") * point_gdf.hvplot(\n",
    "    color='red',\n",
    "    crs=watershed.crs.to_wkt(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align our ERA5 data with the prepped FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "aligned_era5 = fcpgtools.align_raster(\n",
    "    xarray_data['precipitation_amount_1hour_Accumulation'],\n",
    "    fdr,\n",
    "    resample_method='bilinear',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aligned_era5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot our basin(s) and point\n",
    "aligned_era5.hvplot.image(\n",
    "    crs=aligned_era5.rio.crs.to_wkt(),\n",
    "    clim=(\n",
    "        aligned_era5.min().item() + 0.00001,\n",
    "        aligned_era5.max().item()\n",
    "    ),\n",
    "    cmap='PuBu',\n",
    "    cnorm='log',\n",
    "    width=600,\n",
    "    height=500,\n",
    "    widget_type='scrubber',\n",
    "    widget_location='bottom',\n",
    "    tiles='StamenTerrainRetina',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒ§ï¸ Calculate flow accumulation over time ðŸŒ§ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "flow_accum = fcpgtools.accumulate_parameter(\n",
    "    fdr,\n",
    "    aligned_era5,\n",
    "    engine='pysheds',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flow_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check that accumulation matches\n",
    "flow_accum[:, 400, 400].hvplot(\n",
    "    x='time',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot our basin(s) and point\n",
    "flow_accum.hvplot.image(\n",
    "    crs=flow_accum.rio.crs.to_wkt(),\n",
    "    clim=(\n",
    "        flow_accum.min().item() + 0.00001,\n",
    "        flow_accum.max().item()\n",
    "    ),\n",
    "    cmap='PuBu',\n",
    "    cnorm='log',\n",
    "    width=600,\n",
    "    height=500,\n",
    "    widget_type='scrubber',\n",
    "    widget_location='bottom',\n",
    "    tiles='StamenTerrainRetina',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
